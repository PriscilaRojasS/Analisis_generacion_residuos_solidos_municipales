# -*- coding: utf-8 -*-
"""Informe parcial DM_G3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mJ6JBYx0sMgxygm9vi3I0rehEGwARxrp
"""

pip install ydata_profiling

pip install kmodes

import pandas as pd
from ydata_profiling import ProfileReport
import numpy as np
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import numpy as np
from kmodes.kprototypes import KPrototypes
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

df = pd.read_excel('/content/dataset_residuos_final.xlsx')
df

#Analisis general del dataset con profiling
profile = ProfileReport(df, title="Reporte de Datos", explorative=True)

profile

#Eliminar duplicados
duplicados = df[df.duplicated(keep=False)]   # todos los duplicados
print("Registros duplicados encontrados:")
print(duplicados)
df.drop_duplicates(inplace=True)

#verificar valores nulos
#Dada la naturaleza del dataset es complicado hallar valores nulos
print(df.isnull().sum())

#Analisis de valores atípicos en variables de interes, más adelante se vuelve a hacer
columna0 = 'GENERACION_PER_CAPITA_MUNICIPAL'

# 1. ESTADÍSTICOS DESCRIPTIVOS BÁSICOS
print("="*50)
print("ANÁLISIS DE OUTLIERS - ESTADÍSTICOS")
print("="*50)
print(df[columna0].describe())

# Cálculo de límites usando el rango intercuartílico (IQR)
Q1 = df[columna0].quantile(0.25)
Q3 = df[columna0].quantile(0.75)
IQR = Q3 - Q1
limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR

print(f"\nLímite inferior (IQR): {limite_inferior}")
print(f"Límite superior (IQR): {limite_superior}")
print(f"Número de outliers potenciales (IQR): {len(df[(df[columna0] < limite_inferior) | (df[columna0] > limite_superior)])}")

# 2. VISUALIZACIÓN CON BOXPLOT
plt.figure(figsize=(10, 6))
sns.boxplot(x=df[columna0])
plt.title(f'Boxplot de {columna0}')
plt.show()

# 3. VISUALIZACIÓN CON HISTOGRAMA Y DISTRIBUCIÓN
plt.figure(figsize=(10, 6))
sns.histplot(df[columna0], kde=True)  # kde=True añade la línea de densidad
plt.axvline(df[columna0].mean(), color='r', linestyle='--', label='Media')
plt.axvline(df[columna0].median(), color='g', linestyle='-', label='Mediana')
plt.title(f'Distribución de {columna0}')
plt.legend()
plt.show()

df['GENERACION_MUN_TDIA'] = pd.to_numeric(df['GENERACION_MUN_TDIA'], errors='coerce')
columna1 = 'GENERACION_MUN_TDIA'
##ACA HABRÁ MUCHOS ATIPICOS, PUES HAY MUNUCIPALIDADES QUE SON, EN TERMINOS DE HABITANTES, HASTA 50 VECES MÁS GRANDES QUE OTRAS O MÁS
# 1. ESTADÍSTICOS DESCRIPTIVOS BÁSICOS
print("="*50)
print("ANÁLISIS DE OUTLIERS - ESTADÍSTICOS")
print("="*50)
print(df[columna1].describe())

# Cálculo de límites usando el rango intercuartílico (IQR)
Q1 = df[columna1].quantile(0.25)
Q3 = df[columna1].quantile(0.75)
IQR = Q3 - Q1
limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR

print(f"\nLímite inferior (IQR): {limite_inferior}")
print(f"Límite superior (IQR): {limite_superior}")
print(f"Número de outliers potenciales (IQR): {len(df[(df[columna1] < limite_inferior) | (df[columna1] > limite_superior)])}")

# 2. VISUALIZACIÓN CON BOXPLOT
plt.figure(figsize=(10, 6))
sns.boxplot(x=df[columna1])
plt.title(f'Boxplot de {columna1}')
plt.show()

# 3. VISUALIZACIÓN CON HISTOGRAMA Y DISTRIBUCIÓN
plt.figure(figsize=(10, 6))
sns.histplot(df[columna1], kde=True)  # kde=True añade la línea de densidad
plt.axvline(df[columna1].mean(), color='r', linestyle='--', label='Media')
plt.axvline(df[columna1].median(), color='g', linestyle='-', label='Mediana')
plt.title(f'Distribución de {columna1}')
plt.legend()
plt.show()

#GRAFICOS SOBRE GENERACION MUN DIARIOS POR CLASFICACIÓN DE CADA MUNI
# Configuración de estilo
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 12

# 1. Agrupar los datos por clasificación MEF y calcular la media
df_agrupado = df.groupby('CLASIFICACION_MUNICIPAL_MEF')['GENERACION_MUN_TDIA'].mean().reset_index()
df_agrupado = df_agrupado.sort_values('GENERACION_MUN_TDIA', ascending=False)

# 2. Crear el gráfico de barras
fig, ax = plt.subplots(figsize=(14, 8))

# Gráfico de barras
barras = ax.bar(df_agrupado['CLASIFICACION_MUNICIPAL_MEF'],
                df_agrupado['GENERACION_MUN_TDIA'],
                color=sns.color_palette("husl", len(df_agrupado)),
                alpha=0.7,
                edgecolor='black',
                linewidth=0.5)

# 3. Personalizar el gráfico
ax.set_title('Generación Municipal de Residuos per Cápita por Día\n por Clasificación MEF',
             fontsize=16, fontweight='bold', pad=20)
ax.set_xlabel('Clasificación Municipal MEF', fontsize=14, fontweight='bold')
ax.set_ylabel('Toneladas per Cápita por Día', fontsize=14, fontweight='bold')

# Rotar etiquetas del eje x para mejor legibilidad
plt.xticks(rotation=45, ha='right')

# Añadir valores en las barras
for barra in barras:
    height = barra.get_height()
    ax.text(barra.get_x() + barra.get_width()/2., height + 0.001,
            f'{height:.3f}',
            ha='center', va='bottom', fontsize=10, fontweight='bold')

# Añadir grid
ax.grid(axis='y', alpha=0.3, linestyle='--')
ax.set_axisbelow(True)

# Ajustar layout
plt.tight_layout()

# 4. Mostrar el gráfico
plt.show()

# 5. (Opcional) Mostrar estadísticas descriptivas
print("=" * 60)
print("ESTADÍSTICAS DESCRIPTIVAS POR CLASIFICACIÓN MEF")
print("=" * 60)
print(df.groupby('CLASIFICACION_MUNICIPAL_MEF')['GENERACION_MUN_TDIA'].describe())

#Serie temporal nacional (Generación municipal anual total)

if {"ANIO", "GENERACION_MUN_TANIO"}.issubset(df.columns):
    serie_anual = (
        df.groupby("ANIO", as_index=False)["GENERACION_MUN_TANIO"]
          .sum()
          .sort_values("ANIO")
    )
    print("\nSerie anual nacional (toneladas):")
    print(serie_anual)

    plt.figure(figsize=(10, 6))
    plt.plot(serie_anual["ANIO"], serie_anual["GENERACION_MUN_TANIO"], marker="o")
    plt.xlabel("Año")
    plt.ylabel("Toneladas anuales")
    plt.title("Generación anual de residuos sólidos municipales (Total nacional)")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Top 5 departamentos por generación anual promedio

df["DEPARTAMENTO"] = df["DEPARTAMENTO"].str.strip()
dept_anual = df.groupby(["DEPARTAMENTO", "ANIO"])["GENERACION_MUN_TANIO"].sum().reset_index()
top5 = (
    dept_anual.groupby("DEPARTAMENTO")["GENERACION_MUN_TANIO"]
    .mean()
    .sort_values(ascending=False)
    .head(5)
    .reset_index()
)

print("\nTop 5 departamentos por generación anual promedio (toneladas):")
print(top5)

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.bar(top5["DEPARTAMENTO"], top5["GENERACION_MUN_TANIO"], color="blue")
for i, v in enumerate(top5["GENERACION_MUN_TANIO"]):
    plt.text(i, v, f"{v:,.0f}", ha="center", va="bottom", fontsize=9)
plt.xlabel("Departamento")
plt.ylabel("Toneladas anuales promedio")
plt.title("Top 5 departamentos por generación anual promedio")
plt.tight_layout()
plt.show()

df["DEPARTAMENTO"] = df["DEPARTAMENTO"].str.strip()


df["DEPARTAMENTO"].unique()

# 1) Correlaciones solo de columnas numéricas
corr = df.select_dtypes(include=["number"]).corr()

# 2) Máscara para mostrar solo el triángulo inferior
mask = np.triu(np.ones_like(corr, dtype=bool))

# 3) Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(
    corr, mask=mask, annot=True, fmt=".2f",
    cmap="RdBu_r", vmin=-1, vmax=1, linewidths=.5,
    cbar_kws={"label": "r (Pearson)"}
)
plt.title("Mapa de correlaciones")
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.show()

##CLUSTERING
#BUSCAR RESPONDER A ALGUNAS PREGUNTAS
#¿Existen grupos de distritos con alta generación de residuos pero baja población?
#¿Cómo se relaciona el tipo de municipalidad con la generación de residuos?

# Variables relevantes para el análisis
variables_clustering = [
    'POB_TOTAL_INEI',           # Población total
    'POB_URBANA_INEI',          # Población urbana
    'GENERACION_MUN_TANIO',     # Generación total de residuos anual
    'GENERACION_PER_CAPITA_MUNICIPAL',  # Generación per cápita
    'TIPO_MUNICIPALIDAD',       # Tipo de municipalidad (categórica)
    'CLASIFICACION_MUNICIPAL_MEF'  # Clasificación MEF (categórica)
]

# Crear subdataset para clustering
df_cluster = df[variables_clustering].copy()

# Codificación de variables categóricas (one-hot encoding)
df_encoded = pd.get_dummies(df_cluster,
                           columns=['TIPO_MUNICIPALIDAD', 'CLASIFICACION_MUNICIPAL_MEF'],
                           prefix=['TIPO', 'CLASIF'])

print("Dimensiones después de codificación:", df_encoded.shape)

# Boxplots para detectar outliers en variables numéricas
#COMO SE SEÑALÓ PREVIAMENTE, EXISTIRÁN MUCHOS VALORES ATIPICOS
#PUES LA GENERACIÓN ESTÁ FUERTEMENTE ARRAIGADA AL TAMAÑO DE LA POBLACIÓN
#HAY MUNICIPALIDADES MUY PEQUEÑAS EN TERMINOS POBLACIONALES
#Y OTRAS SUMAMENTE ENORMES
#AUN ASÍ, PARA ESTE ANALISIS SE CONSIDERA MANTENER LOS ATIPICOS
#POR EJEMPLO, SI QUISIERAMOS ANALIZAR POSTERIORMENTE
#LA EXISTENCIA DE MUNICIPALIDADES PEQUEÑAS, PERO CON GENERACIÓN GRANDE
#NOS CONVIENE DEJAR LOS DATOS REALES TAL CUAL
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Población total
sns.boxplot(y=df_encoded['POB_TOTAL_INEI'], ax=axes[0,0])
axes[0,0].set_title('Boxplot - Población Total')

# Generación total de residuos
sns.boxplot(y=df_encoded['GENERACION_MUN_TANIO'], ax=axes[0,1])
axes[0,1].set_title('Boxplot - Generación Total Residuos')

# Generación per cápita
sns.boxplot(y=df_encoded['GENERACION_PER_CAPITA_MUNICIPAL'], ax=axes[1,0])
axes[1,0].set_title('Boxplot - Generación Per Cápita')

# Población urbana
sns.boxplot(y=df_encoded['POB_URBANA_INEI'], ax=axes[1,1])
axes[1,1].set_title('Boxplot - Población Urbana')

plt.tight_layout()
plt.show()

# Seleccionar solo variables numéricas para escalar
numeric_vars = ['POB_TOTAL_INEI', 'POB_URBANA_INEI', 'POB_URBANA_INEI',
                'GENERACION_MUN_TANIO', 'GENERACION_PER_CAPITA_MUNICIPAL']

# Crear scaler y aplicar transformación
scaler = StandardScaler()
df_scaled = df_encoded.copy()
df_scaled[numeric_vars] = scaler.fit_transform(df_encoded[numeric_vars])

print("Datos escalados - primeras filas:")
print(df_scaled[numeric_vars].head())

#ESTADISTICAS POR TIPO MUNICIPALIDAD
stats_tipo_municipalidad = df.groupby('TIPO_MUNICIPALIDAD').agg({

    'GENERACION_MUN_TANIO': ['mean', 'median', 'std', 'count'],
    'GENERACION_PER_CAPITA_MUNICIPAL': ['mean', 'median', 'std'],
    'POB_TOTAL_INEI': ['mean', 'median']
}).round(2)

print("\nEstadísticas por Tipo de Municipalidad:")
print(stats_tipo_municipalidad)

# VISUALIZACIONES PRELIMINARES

# Scatter plot: Población vs Generación de residuos
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='POB_TOTAL_INEI', y='GENERACION_MUN_TANIO',
                hue='CLASIFICACION_MUNICIPAL_MEF', alpha=0.6)
plt.xscale('log')
plt.yscale('log')
plt.title('Relación entre Población y Generación de Residuos')
plt.xlabel('Población Total (log)')
plt.ylabel('Generación Total de Residuos (log)')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# Boxplot: Generación per cápita por tipo de municipalidad
plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='TIPO_MUNICIPALIDAD', y='GENERACION_PER_CAPITA_MUNICIPAL')
plt.title('Generación Per Cápita por Tipo de Municipalidad')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print("\n" + "="*60)
print("RESUMEN PRE-CLUSTERING")
print("="*60)
print(f"Total de registros: {df.shape[0]}")
print(f"Variables numéricas para clustering: {numeric_vars}")
print(f"Variables categóricas codificadas: {[col for col in df_encoded.columns if col.startswith(('TIPO_', 'CLASIF_'))]}")
print(f"Datos escalados y listos para clustering: {df_scaled.shape}")

#PRIMERO USAMOS METODOS PARA DETERMINAR EL NUMERO OPTIMO DE CLUSTERS
# Método del codo
inertias = []
silhouette_scores = []
k_range = range(2, 11)
print("\nCalculando métricas para diferentes valores de k...")

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(df_scaled)

    inertias.append(kmeans.inertia_)

    # Silhouette score (excepto para k=1)
    if k > 1:
        silhouette_avg = silhouette_score(df_scaled, cluster_labels)
        silhouette_scores.append(silhouette_avg)
        print(f"K={k}: Inercia = {kmeans.inertia_:.2f}, Silhouette = {silhouette_avg:.3f}")
    else:
        silhouette_scores.append(np.nan)

# Graficar método del codo y silhouette score
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

# Gráfico del codo
ax1.plot(k_range, inertias, 'bo-', alpha=0.7, linewidth=2, markersize=8)
ax1.set_xlabel('Número de Clusters (k)')
ax1.set_ylabel('Inercia (Within-Cluster Sum of Squares)')
ax1.set_title('Método del Codo')
ax1.grid(True, alpha=0.3)
# Gráfico de silhouette score
ax2.plot(k_range[1:], silhouette_scores[1:], 'go-', alpha=0.7, linewidth=2, markersize=8)
ax2.set_xlabel('Número de Clusters (k)')
ax2.set_ylabel('Silhouette Score')
ax2.set_title('Silhouette Score por Número de Clusters')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 3. SELECCIÓN DEL K ÓPTIMO BASADO EN LAS MÉTRICAS

# Encontrar k óptimo (máximo silhouette score)
optimal_k_silhouette = k_range[np.argmax(silhouette_scores[1:]) + 1]
optimal_silhouette = max(silhouette_scores[1:])

print(f"\nK óptimo basado en Silhouette Score: {optimal_k_silhouette}")
print(f"Silhouette Score máximo: {optimal_silhouette:.3f}")

# También considerar el "codo" en la gráfica de inercia
# Calcular la segunda derivada para encontrar el punto de inflexión
inertia_diff = np.diff(inertias)
inertia_diff_ratio = np.diff(inertia_diff) / inertia_diff[:-1]
optimal_k_elbow = k_range[np.argmin(inertia_diff_ratio) + 2]

print(f"K sugerido por método del codo: {optimal_k_elbow}")

# Seleccionar k final (convenimos en usar k=4, del analisis de los coeficientes obtenidos en ambos metodos)
k_final = 4
print(f"K final seleccionado: {k_final}")

print(f"\nAplicando K-Means con k={k_final}...")

kmeans_final = KMeans(n_clusters=k_final, random_state=42, n_init=20)
df_scaled['CLUSTER'] = kmeans_final.fit_predict(df_scaled)

# Añadir clusters al dataframe original para análisis
df['CLUSTER'] = df_scaled['CLUSTER']

print("K-Means completado exitosamente!")
print(f"Distribución de clusters:")
cluster_distribution = df['CLUSTER'].value_counts().sort_index()
print(cluster_distribution)

# 5. ANÁLISIS DE LOS CLUSTERS - VARIABLES ORIGINALES


print("\n" + "="*60)
print("ANÁLISIS DETALLADO DE CLUSTERS")
print("="*60)

# Variables clave para el análisis
key_variables = [
    'POB_TOTAL_INEI', 'POB_URBANA_INEI',
    'GENERACION_MUN_TANIO', 'GENERACION_PER_CAPITA_MUNICIPAL'
]

# Análisis por cluster
cluster_analysis = df.groupby('CLUSTER').agg({
    'POB_TOTAL_INEI': ['count', 'mean', 'median', 'std'],
    'POB_URBANA_INEI': ['mean', 'median'],
    'GENERACION_MUN_TANIO': ['mean', 'median', 'sum'],
    'GENERACION_PER_CAPITA_MUNICIPAL': ['mean', 'median'],
    'TIPO_MUNICIPALIDAD': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'N/A',
    'CLASIFICACION_MUNICIPAL_MEF': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'N/A'
}).round(2)

# Renombrar columnas para mejor legibilidad
cluster_analysis.columns = ['_'.join(col).strip() for col in cluster_analysis.columns.values]
print(cluster_analysis)

# 6.1 ¿Existen grupos con alta generación pero baja población?
print("\n1. ANÁLISIS: ALTA GENERACIÓN vs BAJA POBLACIÓN")

umbral_alta_generacion = df['GENERACION_MUN_TANIO'].quantile(0.60)  # antes 0.75
umbral_baja_poblacion = df['POB_TOTAL_INEI'].quantile(0.40)         # antes 0.25

alta_gen_baja_pob = df[
    (df['GENERACION_MUN_TANIO'] > umbral_alta_generacion) &
    (df['POB_TOTAL_INEI'] < umbral_baja_poblacion)
]

print(f"• Umbral alta generación: {umbral_alta_generacion:.0f} ton/año")
print(f"• Umbral baja población: {umbral_baja_poblacion:.0f} habitantes")
print(f"• Distritos con alta generación y baja población: {len(alta_gen_baja_pob)}")
print(f"• Clusters donde se encuentran: {sorted(alta_gen_baja_pob['CLUSTER'].unique())}")

# Análisis por cluster de esta condición
if len(alta_gen_baja_pob) > 0:
    cluster_analysis_condicion = alta_gen_baja_pob.groupby('CLUSTER').size()
    print(f"• Distribución por cluster:")
    for cluster, count in cluster_analysis_condicion.items():
        total_en_cluster = len(df[df['CLUSTER'] == cluster])
        porcentaje = (count / total_en_cluster) * 100
        print(f"  Cluster {cluster}: {count} distritos ({porcentaje:.1f}% del cluster))")

# 6.2 ¿Cómo se relaciona el tipo de municipalidad con la generación de residuos?
print("\n2. ANÁLISIS: TIPO MUNICIPALIDAD vs GENERACIÓN RESIDUOS")

# Tabla cruzada entre cluster y tipo de municipalidad
cross_tab_tipo = pd.crosstab(df['CLUSTER'], df['TIPO_MUNICIPALIDAD'], normalize='index') * 100
print("Distribución de tipos de municipalidad por cluster (%):")
print(cross_tab_tipo.round(1))

# Tabla cruzada entre cluster y clasificación MEF
cross_tab_clasif = pd.crosstab(df['CLUSTER'], df['CLASIFICACION_MUNICIPAL_MEF'], normalize='index') * 100
print("\nDistribución de clasificación MEF por cluster (%):")
print(cross_tab_clasif.round(1))

# 7. VISUALIZACIÓN DE RESULTADOS

# 7.1 Scatter plot: Población vs Generación (coloreado por cluster)
import matplotlib.cm as cm

# Número de clusters que realmente tenemos
n_clusters = df['CLUSTER'].nunique()

# Crear un mapa de colores con n_clusters
cmap = cm.get_cmap('tab10', n_clusters)

plt.figure(figsize=(12, 8))
scatter = plt.scatter(df['POB_TOTAL_INEI'], df['GENERACION_MUN_TANIO'],
                     c=df['CLUSTER'], cmap=cmap, alpha=0.7, s=60)

# Ajustar la barra de colores con número correcto de ticks
cbar = plt.colorbar(scatter, ticks=range(n_clusters))
cbar.set_label('Cluster')

plt.xscale('log')
plt.yscale('log')
plt.xlabel('Población Total (log scale)')
plt.ylabel('Generación Total de Residuos (log scale)')
plt.title('Clusters: Población vs Generación de Residuos\n(Círculos = Alta Generación/Baja Población)')
plt.grid(True, alpha=0.3)

# Destacar distritos con alta generación/baja población
if len(alta_gen_baja_pob) > 0:
    plt.scatter(alta_gen_baja_pob['POB_TOTAL_INEI'],
                alta_gen_baja_pob['GENERACION_MUN_TANIO'],
                facecolors='none', edgecolors='green', s=100,
                label='Alta Generación/Baja Población')
    plt.legend()

plt.tight_layout()
plt.show()

# 7.2 Boxplot: Generación per cápita por cluster
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x='CLUSTER', y='GENERACION_PER_CAPITA_MUNICIPAL', palette='tab10')
plt.title('Distribución de Generación Per Cápita por Cluster')
plt.ylabel('Generación Per Cápita (ton/hab/año)')
plt.xlabel('Cluster')
plt.grid(True, alpha=0.3)
plt.show()

#8. PERFILADO DETALLADO DE CLUSTERS

print("\n" + "="*60)
print("PERFILES DE CLUSTERS - RESUMEN EJECUTIVO")
print("="*60)

for cluster_id in range(k_final):
    cluster_data = df[df['CLUSTER'] == cluster_id]

    print(f"\n CLUSTER {cluster_id} ({len(cluster_data)} distritos)")
    print("-" * 50)

    # Características demográficas
    print(f" CARACTERÍSTICAS DEMOGRÁFICAS:")
    print(f"   • Población promedio: {cluster_data['POB_TOTAL_INEI'].mean():.0f} hab")
    print(f"   • Población urbana promedio: {cluster_data['POB_URBANA_INEI'].mean():.0f} hab")
    print(f"   • Urbanización: {(cluster_data['POB_URBANA_INEI'].mean() / cluster_data['POB_TOTAL_INEI'].mean() * 100):.1f}%")

    # Características de residuos
    print(f"  GENERACIÓN DE RESIDUOS:")
    print(f"   • Generación total promedio: {cluster_data['GENERACION_MUN_TANIO'].mean():.0f} ton/año")
    print(f"   • Generación per cápita: {cluster_data['GENERACION_PER_CAPITA_MUNICIPAL'].mean():.2f} ton/hab/año")
    # Características institucionales
    tipo_comun = cluster_data['TIPO_MUNICIPALIDAD'].mode()[0]
    clasif_comun = cluster_data['CLASIFICACION_MUNICIPAL_MEF'].mode()[0]

    print(f"  CARACTERÍSTICAS INSTITUCIONALES:")
    print(f"   • Tipo municipalidad predominante: {tipo_comun}")
    print(f"   • Clasificación MEF predominante: {clasif_comun}")

    # Identificar si es cluster problemático (alta generación/baja población)
    problem_count = len(cluster_data[
        (cluster_data['GENERACION_MUN_TANIO'] > umbral_alta_generacion) &
        (cluster_data['POB_TOTAL_INEI'] < umbral_baja_poblacion)
    ])

    if problem_count > 0:
        print(f"  DISTRITOS PROBLEMÁTICOS: {problem_count} con alta generación/baja población")

#9. ANÁLISIS DE COMPONENTES PRINCIPALES (OPCIONAL - PARA VISUALIZACIÓN)


from sklearn.decomposition import PCA

# Aplicar PCA para visualización 2D/3D
pca = PCA(n_components=2)
pca_result = pca.fit_transform(df_scaled.drop('CLUSTER', axis=1))

# Crear dataframe para visualización PCA
pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])
pca_df['CLUSTER'] = df_scaled['CLUSTER'].values

print(f"\nVarianza explicada por componentes PCA:")
print(f"PC1: {pca.explained_variance_ratio_[0]:.3f} ({pca.explained_variance_ratio_[0]*100:.1f}%)")
print(f"PC2: {pca.explained_variance_ratio_[1]:.3f} ({pca.explained_variance_ratio_[1]*100:.1f}%)")
print(f"Total: {pca.explained_variance_ratio_.sum():.3f} ({pca.explained_variance_ratio_.sum()*100:.1f}%)")

# Visualización PCA
plt.figure(figsize=(10, 8))
scatter = plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['CLUSTER'],
                     cmap=cmap, alpha=0.7, s=50)
plt.colorbar(scatter, label='Cluster')
plt.xlabel(f'Componente Principal 1 ({pca.explained_variance_ratio_[0]*100:.1f}% varianza)')
plt.ylabel(f'Componente Principal 2 ({pca.explained_variance_ratio_[1]*100:.1f}% varianza)')
plt.title('Visualización de Clusters en 2D (PCA)')
plt.grid(True, alpha=0.3)
plt.show()

